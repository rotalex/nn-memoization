{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "#from tqdm import tqdm\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION AND EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_path = \"datasets/1.csv\"\n",
    "dataset1 = pd.read_csv(dataset1_path)\n",
    "dataset2_path = \"datasets/2.csv\"\n",
    "dataset2 = pd.read_csv(dataset2_path)\n",
    "dataset3_path = \"datasets/3.csv\"\n",
    "dataset3 = pd.read_csv(dataset3_path)\n",
    "dataset4_path = \"datasets/4.csv\"\n",
    "dataset4 = pd.read_csv(dataset4_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12 = pd.concat([dataset1, dataset2.add([2, 0, 0, 0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_path = \"datasets/3.csv\"\n",
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "dataset[\"in1\"].hist(bins=40)\n",
    "hist, bins = np.histogram(dataset[\"in1\"], bins=2)\n",
    "#print(hist, bins)\n",
    "norm_hist = hist / len(dataset)\n",
    "#scipy.stats.entropy(norm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "dataset[\"in2\"].hist(bins=40)\n",
    "hist, bins = np.histogram(dataset[\"in2\"], bins=250)\n",
    "#print(hist, bins)\n",
    "norm_hist = hist / len(dataset)\n",
    "scipy.stats.entropy(norm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "dataset[\"out1\"].hist(bins=40)\n",
    "hist, bins = np.histogram(dataset[\"out1\"], bins=250)\n",
    "#print(hist, bins)\n",
    "norm_hist = hist / len(dataset)\n",
    "scipy.stats.entropy(norm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "dataset[\"out2\"].hist(bins=40)\n",
    "hist, bins = np.histogram(dataset[\"out2\"], bins=250)\n",
    "#print(hist, bins)\n",
    "norm_hist = hist / len(dataset)\n",
    "scipy.stats.entropy(norm_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from itertools import cycle, islice\n",
    "\n",
    "\n",
    "kMeans = MiniBatchKMeans(n_clusters=16)  \n",
    "\n",
    "dataset_path = \"datasets/3.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "X = dataset[['in2', 'out1', 'out2']].values\n",
    "kMeans.fit_predict(X)\n",
    "y_pred = kMeans.labels_\n",
    "colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                             '#f781bf', '#a65628', '#984ea3',\n",
    "                                             '#999999', '#e41a1c', '#dede00']),\n",
    "                                      int(max(y_pred) + 1))))\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], color=colors[y_pred])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30, 20]\n",
    "for i in range(len(dataset)):\n",
    "    color = \"r\" if dataset.iloc[i][\"in1\"] == 0 else \"b\"\n",
    "    if color != 'r':\n",
    "        continue\n",
    "    plt.plot(np.array(range(0, 4)), dataset.iloc[i], f\"{color}-\", scaley=True)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def color(sample, bit = 0):\n",
    "    if sample & (1 << bit):\n",
    "        return 'r'\n",
    "    return 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "zero_data = dataset[\"in1\"] == 0\n",
    "ones_data = dataset[\"in1\"] == 1\n",
    "\n",
    "for i in range(len(dataset[zero_data][\"in2\"])):\n",
    "    plt.scatter(dataset[zero_data][\"in2\"].iloc[i], dataset[zero_data][\"out1\"].iloc[i], c=color(dataset[zero_data][\"out1\"].iloc[i], 1))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach was to train a neural netowkr to predict the numbers from the inputs directly but id did not work.\n",
    "The next approaches switched into interperting the inputs and outpus as vectors of bits/nibbles. The following code contains\n",
    "logic for octal representation of the numbers and binary representation of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SmallestNN(2, 2) does not work\n",
    "#model = SmallestNNDecoderLike(2, 2) does not not work\n",
    "#model = SmallestNNDecoderLikeV2(2, 2) does not work\n",
    "#model = SmallestNNDecoderLikeV2(1, 1) does not work\n",
    "#model = SmallestNNBitVectV2(16, 512, 512, 16) # Epochs: 250;  Accuracy: 0.97; Time: ~5minutes\n",
    "#model = SmallestCNNBitVect(16, 16) # does not learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from models import *\n",
    "from experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SmallestNNDatasetBitEncodedToKthBit(SmallestNNDatasetBitEncodedMinusOne2One(dataset), 0)\n",
    "\n",
    "def viz(idx):\n",
    "    print(\"Index:\", idx, ds[idx])\n",
    "\n",
    "interact(viz, idx=(0, len(ds) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss = SmallestNNDatasetBitEncodedMinusOne2One(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssss = SmallestNNDatasetBitEncodeNormalized2BitOneHot(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OctBaseReprExperiment(Experiment):\n",
    "    def __init__(self):\n",
    "        super(OctBaseReprExperiment, self).__init__(\n",
    "            SmallestNNBitVectV2(4, 512, 512, 4).to(device),\n",
    "            DataLoader(SmallestNNDatasetBitEncodedBaseK(dataset), batch_size=1, shuffle=True),\n",
    "            DataLoader(SmallestNNDatasetBitEncodedBaseK(dataset), batch_size=1, shuffle=True),\n",
    "            torch.optim.Adam,\n",
    "            torch.nn.MSELoss(),\n",
    "            device\n",
    "        )\n",
    "    \n",
    "    def evaluate(self):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        correct = 0 \n",
    "        for batch in self.test_data:\n",
    "            input, label = batch\n",
    "            input = input.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            predct = self.model(input)\n",
    "            \n",
    "            predct = decode(dec2hex(predct.detach().cpu()).view(1, 16))\n",
    "            label = decode(dec2hex(label.detach().cpu()).view(1, 16))\n",
    "            correct += (predct == label).sum() / 2.0\n",
    "        correct = correct.float()\n",
    "        return (correct / len(self.test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = OctBaseReprExperiment()\n",
    "#trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OctBaseReprCNNExperiment(Experiment):\n",
    "    def __init__(self):\n",
    "        super(OctBaseReprCNNExperiment, self).__init__(\n",
    "            SmallestCNNBitVect(4, 4).to(device),\n",
    "            DataLoader(SmallestNNDatasetBitEncodedBaseK(dataset, 1), batch_size=1, shuffle=True),\n",
    "            DataLoader(SmallestNNDatasetBitEncodedBaseK(dataset, 1), batch_size=1, shuffle=True),\n",
    "            torch.optim.Adam,\n",
    "            torch.nn.MSELoss(),\n",
    "            device\n",
    "        )\n",
    "    \n",
    "    def evaluate(self):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        correct = 0 \n",
    "        for batch in self.test_data:\n",
    "            input, label = batch\n",
    "            input = input.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            predct = self.model(input)\n",
    "            predct = decode(dec2hex(predct.detach().cpu()).view(1, 16))\n",
    "            label = decode(dec2hex(label.detach().cpu()).view(1, 16))\n",
    "            correct += (predct == label).sum() / 2.0\n",
    "        correct = correct.float()\n",
    "        return (correct / len(self.test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = OctBaseReprCNNExperiment()\n",
    "#trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryReprExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = SmallestNNBitVectV2(16, 352, 384, 16).to(device),\n",
    "        train_data = DataLoader(SmallestNNDatasetBitEncodedMinusOne2One(dataset), batch_size=1, shuffle=True),\n",
    "        test_data = DataLoader(SmallestNNDatasetBitEncodedMinusOne2One(dataset), batch_size=1, shuffle=True),\n",
    "        optimizer_class = torch.optim.Adam,\n",
    "        criterion = torch.nn.MSELoss(),\n",
    "        device = device,\n",
    "        epochs = 10000,\n",
    "        decode = None\n",
    "    ):\n",
    "        super(BinaryReprExperiment, self).__init__(\n",
    "            model, train_data, test_data, optimizer_class, criterion, device, epochs, decode\n",
    "        )\n",
    "    \n",
    "    def evaluate(self):\n",
    "        T = torch.Tensor([0.5]).to(device)  # threshold\n",
    "        correct = 0\n",
    "        for batch in self.test_data:\n",
    "            input, label = batch # human_understandable_*\n",
    "            input = input.to(device).unsqueeze(0)\n",
    "            label = label.to(device)\n",
    "            predct = self.model(input)[0]\n",
    "            predct = (predct > T).float() * 1\n",
    "            \n",
    "            if self.decode:\n",
    "                predct = sel.decode(predct)\n",
    "            else:\n",
    "                predct = decode(predct)\n",
    "\n",
    "            if self.decode:\n",
    "                label = sel.decode(label)\n",
    "            else:\n",
    "                label = decode(label)\n",
    "\n",
    "            correct += (predct == label).float().sum() / 2.0\n",
    "\n",
    "        return (correct.float() / len(self.test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = BinaryReprExperiment()\n",
    "#trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(trn.model, \"dataset2_ln16x320x320x16_acc1.0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SmallestNNDatasetBitEncodedMinusOne2One(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(idx):\n",
    "    print(f\"DF[{idx}]=\\n\", dataset.iloc[idx])\n",
    "    sample = ds[idx]\n",
    "    print(f\"Human undersntadable \\nInput={decode(np.expand_dims(ds[idx][0], 0))} \\nOutput={decode(np.expand_dims(ds[idx][1], 0))}\")\n",
    "    pred = traced_script_module(sample[0])\n",
    "    print(f\"raw pred {pred}\")\n",
    "    pred = (pred > T).float()\n",
    "    print(f\"refined pred {pred}\")\n",
    "    print(f\"Human undersntadable pred:\\n\", decode(pred.cpu()).numpy()[0])\n",
    "    print(f\" {decode(ds[idx][1])[0].numpy()}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interact(check_model, idx=(0,len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryReprConvNNExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = SmallestCNNBitVect(16, 16).to(device),\n",
    "        train_data = DataLoader(SmallestNNDatasetBitEncodedMinusOne2One(dataset), batch_size=1, shuffle=True),\n",
    "        test_data = DataLoader(SmallestNNDatasetBitEncodedMinusOne2One(dataset), batch_size=1, shuffle=True),\n",
    "        optimizer_class = torch.optim.Adam,\n",
    "        criterion = torch.nn.MSELoss(),\n",
    "        device = device,\n",
    "        epochs = 10000,\n",
    "        decode = None\n",
    "    ):\n",
    "        super(BinaryReprConvNNExperiment, self).__init__(\n",
    "            model, train_data, test_data, optimizer_class, criterion, device, epochs\n",
    "        )\n",
    "    \n",
    "    def train(self):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        losses = []\n",
    "        moment = []\n",
    "        acc = 0\n",
    "\n",
    "        for e in tqdm(range(self.epochs)):\n",
    "            cum_loss = 0\n",
    "            for batch in self.train_data:\n",
    "                input, label = batch\n",
    "                input = input.to(self.device)\n",
    "                label = label.to(self.device).float() #.unsqueeze(1).float()\n",
    "                predct = self.model(input)\n",
    "                loss = self.criterion(predct, label)\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "            curr = self.evaluate()\n",
    "            if acc < curr:\n",
    "                acc = curr\n",
    "                print(\"Epoch: %5d:\" % (e), curr)\n",
    "            if acc >= 0.99:\n",
    "                break\n",
    "            self.sched.step(curr.item())\n",
    "\n",
    "            moment.append(e)\n",
    "            losses.append(cum_loss / len(self.train_data))\n",
    "        self.display_learning(moment, losses)\n",
    "    \n",
    "    def evaluate(self):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        T = torch.Tensor([0.5]).to(device)  # threshold\n",
    "        correct = 0 \n",
    "        for batch in self.test_data:\n",
    "            input, label = batch # human_understandable_*\n",
    "            input = input.to(device)#.unsqueeze(1)\n",
    "            label = label.to(device).float() #.unsqueeze(1).float()\n",
    "            predct = self.model(input)[0]\n",
    "            predct = (predct > T).float() * 1\n",
    "            \n",
    "            if self.decode:\n",
    "                predct = self.decode(predct)\n",
    "            else:\n",
    "                predct = decode(predct)\n",
    "            \n",
    "            if self.decode:\n",
    "                label = self.decode(label)\n",
    "            else:\n",
    "                label = decode(label)\n",
    "            correct += predct == label\n",
    "\n",
    "        return (correct.float() / len(self.test_data)).sum() / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = BinaryReprConvNNExperiment()\n",
    "#trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sample)\n",
    "#p = trn.model(sample[0].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallestNNCNNBitPredictor(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallestNNCNNBitPredictor, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=256, kernel_size=16)\n",
    "        mdls.append(nn.Linear(256, 1))\n",
    "        mdls.append(nn.ReLU())\n",
    "        self.seq = nn.Sequential(*mdls)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryReprToBitExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = SmallestNNBitVectV2(16, 256, 2).to(device),\n",
    "        train_data = DataLoader(\n",
    "            SmallestNNDatasetBitEncodedToKthBit(\n",
    "                SmallestNNDatasetBitEncodedMinusOne2One(dataset),\n",
    "                0),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        test_data = DataLoader(\n",
    "            SmallestNNDatasetBitEncodedToKthBit(\n",
    "                SmallestNNDatasetBitEncodedMinusOne2One(dataset),\n",
    "                0),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        optimizer_class = torch.optim.Adam,\n",
    "        criterion = torch.nn.MSELoss(),\n",
    "        device = device,\n",
    "        epochs=1000,\n",
    "        init_weigths = True,\n",
    "        trainable_parameters = None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, train_data, test_data, optimizer_class, criterion, device,\n",
    "            epochs=epochs, init_weigths=init_weigths\n",
    "        )\n",
    "        if not trainable_parameters:\n",
    "            return\n",
    "        \n",
    "        self.opt = optimizer_class(trainable_parameters.parameters(), lr=1e-4)\n",
    "        self.sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.opt, mode='min', factor=0.95, patience=10,\n",
    "            verbose=False, threshold=0.01, min_lr=1e-7, eps=1e-08\n",
    "        )\n",
    "    \n",
    "    def train(self):\n",
    "        #import pdb; pdb.set_trace()\n",
    "        losses = []\n",
    "        moment = []\n",
    "        acc = 0\n",
    "\n",
    "        for e in tqdm(range(self.epochs)):\n",
    "            cum_loss = 0\n",
    "            for batch in self.train_data:\n",
    "                input, label = batch\n",
    "                input = input.to(self.device).unsqueeze(0).float()\n",
    "                label = label.to(self.device).unsqueeze(0).float()\n",
    "                predct = self.model(input)\n",
    "                loss = self.criterion(predct, label)\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "            curr = self.evaluate()\n",
    "            if acc < curr:\n",
    "                acc = curr\n",
    "                print(\"\\rEpoch: %5d:\" % (e), curr, end='')\n",
    "            if acc == 1.0:\n",
    "                break\n",
    "            self.sched.step(curr.item())\n",
    "\n",
    "            moment.append(e)\n",
    "            losses.append(cum_loss / len(self.train_data))\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        self.display_learning(moment, losses)\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        T = torch.Tensor([0.5]).to(device)  # threshold\n",
    "        correct = 0 \n",
    "        for batch in self.test_data:\n",
    "            input, label = batch # human_understandable_*\n",
    "            input = input.to(device)\n",
    "            label = label.to(device).float()\n",
    "            predct = self.model(input)[0]\n",
    "            predct = predct.argmax().item()\n",
    "            label = label.argmax().item()\n",
    "            #print(predct, label)\n",
    "            correct += float(predct == label)\n",
    "\n",
    "        return torch.Tensor([(correct / len(self.test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trn = BinaryReprToBitExperiment()\n",
    "#trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "train_data_explicit = SmallestNNDatasetBitEncodedMinusOne2One(dataset)\n",
    "train_data = SmallestNNDatasetBitEncodedToKthBit(SmallestNNDatasetBitEncodedMinusOne2One(dataset), 0)\n",
    "#print(len(train_data))\n",
    "\n",
    "def viz(idx):\n",
    "    print(\"Index:\", idx)\n",
    "    pprint(train_data_explicit[idx][0])\n",
    "    pprint(train_data_explicit[idx][1])\n",
    "    print(\"=\" * 50)\n",
    "    pprint(train_data[idx][0])\n",
    "    pprint(train_data[idx][1])\n",
    "    print(\"target class:\", train_data[idx][1].argmax())\n",
    "    out = trn.model(train_data[idx][0].unsqueeze(0).cuda())[0].cpu()\n",
    "    print(\"predct_class:\", out.argmax().item())\n",
    "    print(out)\n",
    "\n",
    "interact(viz, idx=(0, len(train_data) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since predicting all the 16 bits is ineficient since the algebra inside the NN multiplies matrixes o shape (input_size, output_size) we to have 16 prediction heads for each bit separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallestCNNBits(torch.nn.Module):\n",
    "    def __init__(self, *sizes):\n",
    "        super().__init__()\n",
    "        \n",
    "        mdls = []\n",
    "        feature_sizes = sizes[:-1]\n",
    "\n",
    "        for (inp, out) in zip(feature_sizes[:-1], feature_sizes[1:]):\n",
    "            mdls.append(nn.Linear(inp, out))\n",
    "            mdls.append(nn.LeakyReLU())\n",
    "        \n",
    "        self.common = nn.Sequential(*mdls)\n",
    "        feature_out, network_out = sizes[-2], sizes[-1]\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(feature_out, network_out),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for _ in range(16) # because we predict 16 bits\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        common = self.common(x)\n",
    "        return [head(common) for head in self.heads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset12)\n",
    "#dataset = dataset12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datas = SmallestNNDatasetBitListEncoding(SmallestNNDatasetBitEncodedMinusOne2One(dataset))\n",
    "#datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryReprToBitsExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = SmallestNNBits(16, 768, 2).to(device),\n",
    "        train_data = DataLoader(\n",
    "            SmallestNNDatasetBitListEncoding(SmallestNNDatasetBitEncodedMinusOne2One(dataset12)),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        test_data = DataLoader(\n",
    "            SmallestNNDatasetBitListEncoding(SmallestNNDatasetBitEncodedMinusOne2One(dataset12)),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        optimizer_class = torch.optim.Adam,\n",
    "        criterion = torch.nn.MSELoss(),\n",
    "        device = device\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, train_data, test_data, optimizer_class, criterion, device\n",
    "        )\n",
    "        \n",
    "        heads_parameters = []\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"head\" in name:\n",
    "                heads_parameters.append(param)\n",
    "        heads_parameters = nn.ParameterList(heads_parameters)\n",
    "            \n",
    "        self.opt_heads = optimizer_class(heads_parameters, lr=1e-4)\n",
    "        self.sched_heads = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.opt_heads, mode='min', factor=0.95, patience=10,\n",
    "            verbose=False, threshold=0.01, min_lr=1e-7, eps=1e-08\n",
    "        )\n",
    "    \n",
    "    def train_chunk(self, isTrainCommon: bool = True, headIndex: int = 0):\n",
    "       \n",
    "        predictor_nth_bit = nn.Sequential(self.model.common, self.model.heads[headIndex])\n",
    "        trainable_params = None\n",
    "        \n",
    "        if not isTrainCommon:\n",
    "            trainable_params = nn.Sequential(self.model.heads[headIndex])\n",
    "        \n",
    "        return BinaryReprToBitExperiment(\n",
    "            model = predictor_nth_bit,\n",
    "            device = self.device,\n",
    "            epochs=1500,\n",
    "            init_weigths = isTrainCommon, # if we train common then we need all layers initialized\n",
    "            trainable_parameters = trainable_params\n",
    "        )\n",
    "    \n",
    "    def train(self, headOrder = []):\n",
    "        if not headOrder:\n",
    "            headOrder = list(range(16))\n",
    "        \n",
    "        self.bitIdx2Trainer = {}\n",
    "\n",
    "        self.bitIdx2Trainer[headOrder[0]] = self.train_chunk(\n",
    "            isTrainCommon=True,\n",
    "            headIndex=headOrder[0])\n",
    "        \n",
    "        for headIdx in range(1, 16):\n",
    "            self.bitIdx2Trainer[headOrder[headIdx]] = self.train_chunk(\n",
    "                isTrainCommon=False,\n",
    "                headIndex=headOrder[headIdx])\n",
    "        \n",
    "        for headIdx in headOrder:\n",
    "            self.bitIdx2Trainer[headIdx].train()\n",
    "            \n",
    "        print(\"After training:\")\n",
    "        for headIdx in headOrder:\n",
    "            print(f\"Head {headIdx} evaluate: -> {self.bitIdx2Trainer[headIdx].evaluate()}\")\n",
    "\n",
    "    def evaluate(self):\n",
    "        correct_cnt = 0 \n",
    "        correct_bits = 0\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        for (input, label) in self.test_data:\n",
    "            label = label.to(self.device).float()\n",
    "            prediction = self.model(input.to(self.device))[0]\n",
    "            \n",
    "            all_bits_correct = True\n",
    "            for (predicted_bit, target_bit) in zip(label, prediction):\n",
    "                predicted_bit = predicted_bit.argmax().float()\n",
    "                target_bit = target_bit.argmax().float()\n",
    "                \n",
    "                correct_bit = (predicted_bit == target_bit)\n",
    "                all_bits_correct = all_bits_correct and correct_bit\n",
    "                correct_bits += correct_bit\n",
    "\n",
    "            correct_cnt += float(all_bits_correct)\n",
    "\n",
    "        return (correct_cnt / len(self.test_data)), correct_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "trn2 = BinaryReprToBitsExperiment()\n",
    "trn2.train_chunk(isTrainCommon=True, headIndex=8).train()\n",
    "trn2.train_chunk(isTrainCommon=False, headIndex=8).evaluate()\n",
    "trn2.train_chunk(isTrainCommon=False, headIndex=15).evaluate()\n",
    "trn2.train_chunk(isTrainCommon=False, headIndex=15).train()\n",
    "trn2.train_chunk(isTrainCommon=False, headIndex=15).evaluate()\n",
    "trn2.train_chunk(isTrainCommon=False, headIndex=8).evaluate()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn2 = BinaryReprToBitsExperiment()\n",
    "trn2.train(list(range(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trn = BinaryReprToBitsExperiment()\n",
    "trn.train([8, 15, 14, 0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn = BinaryReprToBitsExperiment()\n",
    "#trn.train([8, 15, 0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trn.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryReprToBitsOneHotExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model = SmallestNNBitsOneHot(16, 512, 16).to(device),\n",
    "        train_data = DataLoader(\n",
    "            SmallestNNDatasetBitEncodeNormalized2BitOneHot(dataset),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        test_data = DataLoader(\n",
    "            SmallestNNDatasetBitEncodeNormalized2BitOneHot(dataset),\n",
    "            batch_size=1,\n",
    "            shuffle=True),\n",
    "        optimizer_class = torch.optim.Adam,\n",
    "        criterion = torch.nn.MSELoss(),\n",
    "        device = device\n",
    "    ):\n",
    "        super().__init__(\n",
    "            model, train_data, test_data, optimizer_class, criterion, device\n",
    "        )    \n",
    "\n",
    "    def train(self, headOrder = []):\n",
    "        losses = []\n",
    "        moment = []\n",
    "        acc = 0\n",
    "\n",
    "        for e in tqdm(range(self.epochs)):\n",
    "            cum_loss = 0\n",
    "            for batch in self.train_data:\n",
    "                input, label = batch\n",
    "                input = input.to(self.device)\n",
    "                label = label.to(self.device)\n",
    "                \n",
    "                #import pdb; pdb.set_trace()\n",
    "                \n",
    "                predct = self.model(input)\n",
    "                loss = self.criterion(label, predct)\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                cum_loss += loss.item()\n",
    "\n",
    "            curr_acc, curr_bit_acc = self.evaluate()\n",
    "            if acc < curr_acc:\n",
    "                acc = curr_acc\n",
    "                print(\"\\rEpoch: %5d:\" % (e), curr_acc, curr_bit_acc, end='')\n",
    "            if acc >= 0.9999:\n",
    "                break\n",
    "            self.sched.step(curr_acc)\n",
    "\n",
    "            moment.append(e)\n",
    "            losses.append(cum_loss / len(self.train_data))\n",
    "        self.display_learning(moment, losses)\n",
    "\n",
    "    def evaluate(self):\n",
    "        total_correct_cnt = 0 \n",
    "        total_correct_bits = 0\n",
    "        \n",
    "        #import pdb; pdb.set_trace()\n",
    "        for (input, label) in self.test_data:\n",
    "            label = label.to(self.device).float()\n",
    "            prediction = self.model(input.to(self.device))\n",
    "            #import pdb; pdb.set_trace()\n",
    "            \n",
    "            label_bits = label.argmax(2)\n",
    "            predicted_bits = prediction.argmax(2)\n",
    "            \n",
    "            correct_bits = (predicted_bits == label_bits).float().sum().item()\n",
    "            \n",
    "            total_correct_bits += correct_bits\n",
    "            total_correct_cnt += float(correct_bits == 16)\n",
    "\n",
    "        return (total_correct_cnt / len(self.test_data)), total_correct_bits / len(self.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = BinaryReprToBitsOneHotExperiment()\n",
    "trn.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osnn",
   "language": "python",
   "name": "osnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
